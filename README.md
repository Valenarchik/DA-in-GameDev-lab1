# РАЗРАБОТКА СИСТЕМЫ МАШИННОГО ОБУЧЕНИЯ 
Отчет по лабораторной работе #5 выполнил(а):
- Мокрушин Павел Михайлович
- РИ210932

Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 80 |
| Задание 2 | * | 20 |

## Цель работы
Интеграция экономической системы в проект Unity и обучение ML-Agent.

## Задание 1 и Задание 2
### Измените параметры файла.yaml-агента и определить какие параметры и как влияют на обучение модели. Опишите результаты, выведенные в TensorBoard. 
Изначально решил просто прогнать тот .yaml-файл, который уже присутсвовал в проекте, а потом решил с ним поэкспериментировать.

<img width=100% src="https://user-images.githubusercontent.com/101575777/205045801-66a38add-2ace-40b0-934c-049eca630feb.png" />

---

Открыл .yaml-файл и первое что изменил это max_steps(сколько итераций всего надо сделать) на 100000, так как я явно не стану обучать нейросеть дольше(да это и не нужно). Далее решил поэкспериментировать с batch_size и buffer_size, заметил одну закономерность buffer_size в 10 раз больше batch_size, сперва решил не изметь эту пропорцию, а просто уменьшил их до 100 и 1000 соответственно (вместо 1024 и 10240). Как видно успешность обучения не изменилась, а вот потери (Value Loss) вырости в примерно в 10 раз.

<img width=100% src="https://user-images.githubusercontent.com/101575777/205047864-8aef02c9-b42f-483c-9405-b946d2fac0b9.png" />

---

Решил еще раз меньшить batch_size и buffer_size в 10раз. Когда начал опучение, то сразу заметил некоторые подвисания раз в 4-5секунд, я так предполагаю, что это подведение неких итогов между буферами, они стали проходить чаще. При этом, сильное уменьшение этих параметров плохо сказалось на обучении, оно стало происходить дольше.

<img width=100% src="https://user-images.githubusercontent.com/101575777/205051136-5705c884-6741-4930-871c-65c3360010b7.png" />

---

Поэтому я откатил изменения к 100 и 1000 соответственно и решил поменять пропорции не 1:10, а 1:20. Теперь видимо обучение проходит настолько быстро, что это даже не успевают зафиксировать.  

<img width=100% src="https://user-images.githubusercontent.com/101575777/205055214-beeccfda-23a2-4059-9946-c03164afb5c6.png" />

И вправду, даже Unity это подтверждает у нас не инфляция, а дифляция вообще.

![8](https://user-images.githubusercontent.com/101575777/205055508-dfa242db-2ee8-4983-a246-b60aff8f782d.png)

---

Еще решил изменить вероятность мутации в 8 раз - это параметр beta. И как видно, график стал случайным. Хороший результат вроде и есть, но он не закрепляется из-за постоянных мутаций.

<img width=100% src="https://user-images.githubusercontent.com/101575777/205058610-df67ee4c-043a-4505-9f26-6fbaec1082d7.png" />

---
Затем решил, что увеличу колличество эпох в 2 раза с 3 до 6. Это немного ухудшело обучение и оно стало проходить ощутимо дольше.

<img width=100% src="https://user-images.githubusercontent.com/101575777/205060545-8e8b5cd7-4f77-4f47-94bd-2b13b1a2e9bc.png" />

Вот как было в прошлый раз(скорость выше):
![123123](https://user-images.githubusercontent.com/101575777/205061036-185a24eb-254f-41f6-9867-3062379c1ee4.png)

A вот как сейчас(скорость обучения упала):
![121](https://user-images.githubusercontent.com/101575777/205061181-880d67c0-ff8c-4f46-90cc-4c954d3ebd77.png)

---

Ну и на последок. Мне не очень понравилось оформление в котором происходит обучение. Поэтому я его изменил, чтобы чувствовался антураж.

![Снимок экрана 2022-12-01 181455](https://user-images.githubusercontent.com/101575777/205062114-10dc7c43-ae6f-4128-8feb-07ad8fd3be4d.png)
## Выводы


